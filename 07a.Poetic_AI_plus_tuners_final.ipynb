{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAI_poetic_AI_plus_tuners_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX-NGgpu0stx"
      },
      "source": [
        "Bartoś Edyta, Marcin Grelewicz,\r\n",
        "LSTM generating poems\r\n",
        "As inspiration we used: https://medium.com/predict/creating-a-poem-writer-ai-using-keras-and-tensorflow-16eac157cba6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrN9fZqR8QTu"
      },
      "source": [
        "Import bibliotek\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYFoEu9ukyDM"
      },
      "source": [
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn import model_selection\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "import tensorflow.keras.utils\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhvDkyBP7EwV",
        "outputId": "ce24a947-fc88-4309-b65b-44e0be45053d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWktFBdpgIw"
      },
      "source": [
        "Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Wxse2OWOK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d939068-5407-4902-c3a6-8220aee38d9b"
      },
      "source": [
        "# with keras preprocessing we vectorize our words\r\n",
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "# load data\r\n",
        "data = open('/content/drive/MyDrive/ai_poeta/poems.txt', encoding=\"utf8\").read()\r\n",
        "\r\n",
        "print(tokenizer)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras_preprocessing.text.Tokenizer object at 0x7f2fc029c860>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AME1xgPbIni0"
      },
      "source": [
        "#print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egCHPSXGIgQU"
      },
      "source": [
        "#we lowercase and we call split method to treat sentence as a sequence\r\n",
        "text = data.lower().split(\"\\n\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suA0llnrIv_7",
        "outputId": "400749bf-84d1-4ff2-f722-18c1e66db77c"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fishy business', \"man's got bigger fish \", 'to fry,', 'leaving the smaller fish ', 'to die,', 'still always wondering', 'sadness, why.', \"if livin's easy,\", \"dying's an escape.\", 'if being normal is easy,', 'put on the cape.', 'if being fat is easy,', 'shed all the shape.', 'if speaking is easy,', 'lay down the tape.', '', 'the one who was meant to be-', '', 'when i became we', 'nothing seemed difficult ', 'the world was indeed made of rainbows', 'of unicorns and extra crispy french fries', 'you made me complete', 'yet somehow the darkness never left', 'for the wounds had never healed', 'grey hid behind the curtain of colors', 'wanting to crush the horn of hope', 'i wanted to be me again', 'for the inverted m was never meant to be.', 'you took my heart and put it right', 'it was but my mind dwelling on the sorrows of past', 'my broken teeth, my swollen soul', 'fight had already boarded the flight', 'the one overbooked with my emotions', 'it was never supposed to fly again', 'yet you were the pilot of my dreams', 'my defence against destiny', 'i hope to be your knight in shining armour', 'but you are the one who was meant to be.', '', 'letters of love (lol)', 'it was love', 'at hundred and first sight', 'two years in college', 'we got engaged all right', 'away she went putting the ring on hold', 'while i wrote her letters in bold', 'two times four times twelve times two', 'night seemed darker and day blue', 'we tied the knot in broad daylight', '192 letters needed a rewrite', 'it was after years i found', 'one of them lying around', 'my kids were giggling', \"flowers in my mind of yesteryear's spring\", \"i asked her if she's got the stash\", \"none of your business, mister. it's my cache.\", 'but it was i who bled my heart', 'once you delivered them ,they became my part.', 'i wonder if i should hire a lawyer to get the letters', 'silly things written in love are worth 100 acres.', '', 'the moving train', 'after thirty years', 'of teaching history,', 'she reached out to him', 'a million times,', 'the kids went away', 'to study and to earn a name', 'her history kept her moving', 'in the tear drops of rain.', 'she belonged to her students', 'and never felt sane,', 'the commute of life took away', 'years she could have spent', 'being there when it mattered.', 'space is a luxury not to be given;', 'unless you hide from pain.', \"he saw her gliding through the train's coach\", 'could have hugged her tight', 'but he found himself', 'on the wrong side of the platform.', 'the train had left', 'but a fragment of her behind,', 'her dreams had been achieved', 'through other people in her life.', '\"what will i do when i retire\"', 'she used to quip to him everyday', 'so much to read and write, he would say.', 'have done my fair share, said her mind', 'yet she believed there was still time,', 'time to make things right.', '', 'fight or fluight', 'to erase a cloud hidden', 'he went up the ladder', 'chaos was waiting', 'to help a lending hand', 'the birds flu away', 'one came along', 'his help was unwelcoming', 'megadeath his band', 'things got deleted ', 'memories got corrupt', 'a beam broke through', 'cloudburst and emotions erupt', 'its easy to let go', 'difficult to understand', 'droplets fall on face', 'and sometimes in vein they race', '', 'father,', 'he grew up without one', 'alive yet away', 'catching breath was easy,', 'a ball, not really.', 'in jonty he found', 'the rhodes of life.', 'puberty hits hard', 'but rocky trained his fists', 'the grass of face grew thick and bold', 'moustachey roger backhand ', 'was the best a man could get', 'he learned to love in casablanca', 'and to laugh in modern times', 'the pain never made him cry', 'yet seeing father-son bond on screen would.', 'he was never alone ', 'yet hollow inside.', 'the mode of communication being', 'whatsapp forwards and inspirational videos', 'the day father returned', 'his hands lay numb and face so calm', 'his last message read,', '“before you know it, they’ll be grown', 'you kiss goodnight to that baby', 'every chance you get”', '', 'fear of missing out', 'there is so much to see', 'so much to do,', 'we do it for others', 'when the moon is blue.', 'we feel alone', 'in the world of snaps,', \"stories aren't told\", 'they disappear in a day.', 'memories fade we groan', 'relations difficult to hold.', 'still we cling to life', 'the one wiating for us', \"somebody's sister,someone's wife\", 'love is online,', 's\"mothered\" offline.', 'feeling loved is not enough', \"'tis the age of doubt\", 'we celebrate, we dance', 'in fear of missing out.', '', 'revenge and morose', 'tough to avoid', 'easy to take', 'its the cold dish', 'the angry asteroid.', '', 'getting back at', 'is not the challenge', \"having one's \", 'the real deal.', '', 'red erupts', 'life corrupts', 'vulnerable naked self', 'still thirsty for revenge?', '', 'the meeting place', '', 'hanging by a thread', 'we find love ', 'in dreams we never had.', '', 'we dream through their eyes', 'live enough to chase them', 'till the last sunrise.', '', 'who are you?', 'kimi na no wa.', '', 'my fairy tale.', '', 'life is better;', 'when i think of your gleeful eyes,', 'just when i see a newborn child,', 'while i sleep next to your smiling face.', '', 'life is tough;', 'when i have no one to share my victories with,', 'just because we were never best friends,', 'while i slept on my hand to not feel alone.', '', 'life is hilarious;', 'when you pretend to be my super nerd,', \"just because you'd sometimes shop in the kid's section,\", 'while i ran past the fitness freaks in the morning,', 'to see twilight fall on your hair.', '', 'life is', 'when i write', 'just to hold onto your memory', 'while i dream a little more.', '', 'the crack before dawn', '', 'some have it easy,', 'some have it rough,', 'in heartbreak one finds solace', 'in tears we find love.', 'the blink of an incoming message,', 'the flood inside my heart.', 'replace the old with new', 'replace the memories inside', 'perhaps it was for the best', 'perhaps maybe leave out all the rest', '', \"head's up\", '', 'my dear dream,', 'hiding behind the shadows', 'dancing on petals concealed', 'i lay down on the bed', 'and you arise from slumber', 'enlightening me', 'towards threats unknown', 'nudging me', 'in a maze herculean', 'guiding me', 'to the hidden world,', 'a world radiant enough', 'for this moth to burn', 'a dream worthy enough', 'to chin up to the music. ', '', 'the cart', '', 'my build miniature', 'adventures though colossal', 'i may be ordinary', 'my balloons are not.', 'some hanging by a thread,', 'some soaring towards the silent night', 'a trade occurs and they depart.', 'filling the gap our society can not', 'with gleaming smiles and empty stomachs.', 'one sleeps inside, one fools around', 'the father hustles for a bread half pound.', 'i may be small,', 'i may be in shambles,', 'i might creak in pain', 'i might smile in rain,', 'everyday i go out', 'to let them know', 'humanity awaits', 'at the end of the road.', '', 'missmenot', 'we run away from our troubles', 'our fears, our dears', 'wishing our lives are filled ', 'with colors nice and shiny.', 'each corner echoes', 'the tender intimate warmth', 'we wish to be alone', 'yet yearning for the hand ', 'which once fed you love', 'the one amongst the crowd of many', 'the many-bangled girl', '', 'pain-tingtingting!', '', 'i dream a dream so white and blue', 'a dusty cloud came near and grew', 'sand in my feet wind in my hair', 'through paintings memories i share.', '', 'a dusty ball rolled over into the sea', 'i gathered the colors to paint the ball', 'another ball washed ashore, bigger and bouncy', 'someone had replaced poor dusty', '', 'disheartened yet determined', \"dusty didn't stop rolling\", \"he became a mountain in someone else's painting\", 'i was but a child marching to my own beats.', '', 'i missed the snow so i made it fall', 'a beach to quench my thirst', 'my legs so tiny, my heart so small', 'i thought i was good,', \"but you're the worst.\", '', 'fallacy', '', 'life ends at the edge of the road,', 'the fall may be our last.', '', 'we all made our choices', 'some strong, some weak branches', 'we may have risen from the ashes', 'but the fall may be our last.', '', 'the mountains are but far', 'some scaled, some avoided', 'kept us going in days so gloomy', 'the fall maybe our darkest night.', '', 'layers upon layers we peeled', 'of people who came and loved', 'we could have stopped them from leaving', 'the fall is the one to blame', '', 'lush green bed awaits at the bottom', 'the fall is just the beginning', '', 'little by little', 'his heart became brittle', 'a goodbye was promised', 'by an alchemist unknown', '', 'inch by inch', 'his stature grew', 'the bricks turned orange', 'a visit was overdue', '', 'piece by piece', 'he broke her down', 'the beauty remained', 'the beast had gone', '', 'brick by brick', 'the alchemist was paid in gold', 'he encrypted a moon in marble', 'to date we wonder about his magic trick.', '', 'life in a nutshell', '', 'my dear celery', 'you cost a lot of penne', 'you were supposed to bake', 'my life butter', '', \"my wallet can't ketchup\", 'a petite so wholesome', 'cantaloupe this noodley world', 'bonus cannoli save my life', '', 'its a dog eat dog world', 'i can only let the chips fall', 'honey,do turnip the music', \"we don't carrot all.\", '', 'who am i, in the eyes of most people?', 'a nobody; a non existent entity.', 'someone who has not and never will have', 'any one position in the society.', 'inshort, the lowest of the lows.', 'well then,even if that were all absolutely true,', 'then one day i will have to show by my work ', 'what this nobody,', 'this non-entity has in his heart. ', '', 'every year the box opens,', 'some kites are added,', 'some remain wounded.', '', 'the kite doctor treats them well', 'gives the rocket a shredded bell', 'each has a story to tell.', '', 'they kiss the skies too high', 'and fall to the ground so low', 'some rebel, others defy.', '', 'my dear box i tie you again the day after', 'for it shall hold my childhood dear', 'through kites, my dreams soar', 'through thread, my life restored. ', '', 'hifi!', '', 'music inside all of us', 'yet we fail to see,', 'talent feeds the tornado inside', 'silver keeps the fire burning.', '', 'passion, perseverance,proficiency', 'all they see is pity', 'not all can pay the piper', 'and get out of this fallacy', '', 'smile and the world giggles', 'cry and the nature consoles', 'copper rains in purple hue', 'something numb and something blue', '', 'he decides to settle the score', 'moulding his heart with bitter ore', 'the world is full of flair but,', 'we have no time to stand and stare.', '', 'satisfying con - trolls', '', 'we wish to meet new people', 'talk to strangers', 'have new experiences', 'smile away to the chirpy beetle.', '', 'we feel society stops us', 'controls our emotions', 'but we want their likes', 'on our photos superflous', '', 'you may talk to strangers', 'ignore the ones who care', 'not all are controlling', 'some always remember you in their prayers.', '', 'if i die today', 'i wont be known as the one who loved', \"i'd be known as the one who controlled\", 'but my fate was already sealed', 'when i stopped to let you go.', '', 'hold on to the memories', 'pin them down in your heart', 'it may repair your broken soul,', 'piece by piece make you whole,', 'life is fair, people are just,', 'look in the right direction, we must.', '', 'edgey evening', '', 'somewhere over the horizon i see', 'the place meant for me', 'somewhere in between', 'lies the mysterious sea.', '', 'a song sung so high above', 'splits the seas in two', 'one shapes memories of sorrow', 'other a dancing tree', '', 'i see the promised land', 'consuming the wrath of rain', 'i wish the clouds goodbye', 'for they were not meant for me.', '', 'the promised land is here', 'i wish to be free', 'a call comes from the other side', 'you were never meant to be.', '', 'stay', '', 'life gives us bricks to make walls,', 'no one said where,', 'some build monuments of glory,', 'some erect them in their hearts.', 'a wall was asked once', 'what keeps it up at night,', 'it laughed back and said', 'words and memories of glee,', 'everybody pays a fee', 'not everyone is supposed to play a part in your life,', 'the ink may fade into oblivion,', 'and the story unfinished,', 'what may remain for people to stare,', 'writings on the wall,', 'castles in the air.', '', 'running in the sand', 'crashing with the waves', 'floating through the world', 'is a giant turtle in a cave.', '', 'he hides', 'behind the mistakes of past,', 'as the wick turns to ash', 'diaries of yesterday he holds fast.', '', 'once upon a time', 'the river flew full', 'he swam, he jostled', 'for life had no rule', '', 'he looks towards the ocean', 'to seek solace', 'all he can find is that', \"the water doesn't race.\", '', 'he goes in his shell to find ', 'the missing part numb', 'the puzzle may complete the big picture', 'but you still need a pair to play the drum.', '', 'incomplete he feels', 'desolation prevails', 'waning with the sun,', 'is a giant turtle in the cave.', '', 'maze', '', 'we often feel lost - ', 'in thoughts that betray,', 'on untravelled roads being gray.', 'but when you get lost', \"in a person's life,\", 'you figure out a way', 'to beat the maze.', '', 'you can meet a billion people', 'but only one can be your maze', 'the one in which you can be lost forever,', 'the one who is worth the chase.', '', 'aglet', '', 'the little match girl', 'who painted a picture so clear', 'the world could be seen', 'in the shoes so clean.', '', 'that winter was long ', 'yet she waited for the sun', 'she wanted to show the world', 'that i am a rainbow too ', 'november rains', 'those fickle beauties', 'made her sing a song so great', 'the world around could barely accomodate', '', 'she died the day after ', 'burning bright with fever so high', 'best are the movies', 'with no happy endings', 'no pain to feel,', 'no sorrow to gain.', '', 'moondance', '', \"meet me at the river's end for;\", 'a song needs to be sung,', 'mend, append, pretend my friend,', 'thumping hearts, beating drums;', 'a night to remember, a song to be sung.', '', 'tower by the sea', '', 'i wish there was a way to know', 'how much in life do i owe,', 'curiously i climb the tower of jenga', 'only to fall into a pool of magenta.', '', 'head over heels over a pretty ballerina', 'storms came but i held down the fort,', 'she was messy, i was argentina.', '', 'but god cast a shining spell', 'my head contorting over the carousel', 'fire raged on the banks of still waters', 'one, two, three then came the marauders.', '', 'all i ever wanted was', 'to walk across the hill,', 'to know those were my good days', 'to gift the world one last daffodil.', '', 'the flower hawker', '', 'when the cows moo', 'and the prayer bells ring,', 'he cycles his way through', 'the morning tring.', '', 'be it january or june', 'flowers sway to his tune', 'greeting with a smiling face', 'for he has sadness to erase.', '', 'his health is always in pink', 'his bench is always clean and white,', 'collecting colors to gain green', 'ends up everyday gathering marigold.', '', 'he whips up the best ', 'spots me from a mile away,', 'an unspoken transaction takes place', \"bunch of reds for a penny's pay.\", '', 'some toss coins,', 'some read horoscopes,', 'i know my day will be well', 'if i get that smile', 'and a pretty crimson glory rose.', '', 'the postman', '', 'the doorbell rings', 'but there is no one around', 'he slides it below the door', 'without making a sound.', '', 'letters of love', 'notes of distress', 'some delayed', 'altogetherly delivered', '', 'the rugged clothes have withstood', 'rains and hurricanes', 'all they ask for in return', 'a sign on a wooden pane.', '', 'a stranger to none', 'yet familiar to all', \"amidst the furry's fury\", 'always ready to play ball.', '', 'letters, catalogues, notices', 'may get replaced by email,', \"the postman can't be replaced\", 'for they deliver hope,', 'they care.', '', 'papergal', '', 'why do we wake up?', 'is it hope of future', 'or righting the wrongs of past?', 'daily chores and music to our ears,', 'early walk executed in our brains', 'while we come back to our senses,', 'we hear a loud thud', \"no, poets don't fall\", 'papers do,', 'the dawn of news', 'ricocheting from our wind chimes,', 'orchestrated to hide beneath ', 'the crevices left untouched,', 'the paper gal hits the target', 'which no one else sees.', '', 'methodical madness', '', 'a storm brews inside', 'before the mayhem is unleashed,', 'our mind is satisfied', 'when the beast is set free.', '', 'things may calm us', 'people may hurt us', 'life may beat us', \"but the beast can't be contained.\", '', 'blindsided by our egos', 'backed into a corner', 'our true nature, restrained', 'our egos, altered.', '', 'moral compasses shatter', 'north stars vanish', 'is this the real life', 'or just a sad, mad world.', '', 'a world marked for madness,', 'a world where pandemonium prevails.', 'the world of devil.', '', 'belligerent box', '', 'its tough to find the right place', 'fitting into the world is rough.', '', 'we tape ourselves shut', 'slaming our doors in defiance,', 'some are easy to crack', 'a few are tough nut.', '', 'once the floodgates open', 'we are all the same', 'a pile of emotions stacked up', 'a wandering soul without an aim.', '', 'hitting the mat is just the beginning', 'inner walls need to be resurrected', 'we live to be boxed another day', 'out for delivery, subject to delay.', '', 'clumsy cloud', '', 'a new day, a new yawn', 'darts of sunlight beaming at dawn,', 'never predict where i will be next,', \"as i wait for the ringmaster's text.\", '', 'even my body has 70 percent water,', 'sometimes more than more,', 'jettier the black, bigger the hoarder', 'made of cotton heavier than iron ore।', '', 'i wish to be more transparent,', 'but secrets we need to hide,', 'camouflaging my love i condescend,', \"tears don't fall they get electrified.\", '', 'we merge, diverge, converge in a day,', 'dangling our sorrows in shades of gray,', 'sorrow permeates, joy disseminates', 'while we wait for the silver lining', 'to come and play,', 'its cloudy boy-o,', 'with a chance of rain', '', 'beamish bear', '', 'be here in the present', 'to learn a lesson,', 'affection is pleasant', 'when life gives us lemons.', '', 'acknowledge people ', 'for the good they do,', 'hold their hands', 'when mistakes are due.', '', 'clutch their fingers tight', 'let them know you are there ', 'spare a little gray in white', 'bare a little, forbear.', '', 'the hand that gives meaning', 'may soon fade away', 'all that is left behind', 'ruffled hair, eyes weeping.', '', 'philosophical potboiler', '', 'as the sun rises,', 'everyone compromises;', 'we wake up with hunger', 'to be a little younger.', '', 'the lost games,', 'the flings and flames,', \"weekends and mother's bawl\", 'curled up in a blanket tall.', '', 'ceilings different,', 'bright and dull', 'replaced by dark mirror', \"but charging's null.\", '', 'nostalgia, friendship', 'love and life,', 'living in the words of others', 'while we clip our feathers', '', 'what does one earn', 'with a single like', 'mike oscar november echo yankee', \"haven't seen a friggin dime!\", '', 'implosion', '', 'why do we keep going back', 'to places of pain', 'challenging rage to take over', 'destroying peace of mind, ', 'no restrain.', '', 'machines may learn ', 'from mistakes past,', 'humans fail to comply.', '', 'like moth to the lamp', 'we fly and defy,', 'thoughts to deny', 'pain to personify.', '', 'excelsior', '', 'when nothing', 'is going your way,', 'they say,', 'when its not your time,', 'its not your time.', \"i didn't ask\", 'to be buried under sea,', 'to be bit by a spider,', 'to have a hole in my heart.', 'all i asked,', 'was to create a world,', 'a world for misfits,', 'a universe to live.', 'rest now, o silent green beast.', '', 'mountain mail', '', 'a ship sails', 'over the red mountain', 'and a winter mundane,', 'here lies spring,', 'conceited in a veil.', '', 'as the bag drops', 'in the serene hue,', 'some letters escape', 'to tell their tale.', '', 'she was his taj', 'he was his haram,', 'but the one ', 'who writes destinies', 'left out one detail.', '', 'a moon to gift,', 'a smile to remember,', 'he made it to the top', 'a bit too late,', 'to his sealed fate.', 'a face to remember,', 'a place to sail.', '', 'hyphenseparatedvalue', '', 'hold on -', 'to the dreams you chase,', 'pass on -', 'the knowledge you get,', 'go on -', 'to the edge of the horizon,', '', 'game on -', 'seek the challenging phase,', 'carry on -', 'with the baggage of regret,', 'move on -', 'from teary words to hyphens,', '', 'give up -', 'before its too late,', 'stand up -', 'fight the inner rage,', 'a world divided -', 'by caste and race,', 'an emotion divided-', 'by a space', '', 'restricted airspace', '', 'if you are easy to forget', 'then you did something right.', 'we all are but living ', 'on borrowed time.', '', 'lend a hand,', 'borrow a book.', 'get people on demand,', 'not to love, but only to look.', '', 'filtering noise is easy,', 'its the echo inside', 'which chips away,', 'pound for pound,', 'day by day.', '', 'screams to let out,', 'deep breaths to take,', 'alive online,', \"for borrowed lives' sake.\", '', 'a clumsy day', '', 'alarm missed,', 'sure.', 'waking 2 minutes before one,', 'disaster.', 'hot shower,', 'mon amour!', 'forgetting towel outside,', 'shivering plaster.', '', 'a rose falls on your cheek,', \"today's my day.\", 'cat scratches on your dry skin,', 'nope, not today.', 'will listen to that audiobook on the way,', 'sinful janx spirit!', \"mobile's asleep on the bed at home,\", 'curse you, mcduck!', '', 'what a productive work day,', \"dilbert's happy.\", 'you have 0 new messages screen read in the evening,', 'my anxieties have anxieties.', 'she will probably read the poem, i suppose.', 'a guy can hope,', 'nope, nope, nope.', '', 'the side mirror', '', 'to forgotten chats', 'and incomplete association,', 'i wish to ask this dubious question,', 'how do you know when it ends,', 'the book of life with a broken pen.', '', 'waking up with a poem new', 'messages used to wait in queue,', 'like leaves in autumn ready to fall,', 'pepsi cola candies, november rainfall.', '', 'from madly in love', 'to a broken man,', 'friendships so strong', 'forgotten wingman.', '', 'all it takes is a wake up call', 'one wrong steer into the wall', 'is the path to blame, i question', 'you have a new friend suggestion.', '', 'the peacock and the sun', '', 'sitting in an empty room', 'a picteresque view to consume', 'amongst the green and hay', 'eyespots in a circular array', '', 'out comes a neck so majestic', 'while the sun becomes poetic', 'what is your iridescence without me', 'only good for a mediocre saree.', '', 'the peacock snaps its neck in return', 'screaming by the silly fern', 'see that man by the window', 'do you see him breaking into a crescendo?', '', 'we are but a figment of imagination', 'the bang that made us might even take us', 'why burn so bright in rage,', 'come lets give the man something to gaze.', '', 'the man is but a slave', 'to worries of work and fame,', 'while the sun sets to rise,', 'the peacock provides the flame.', '', 'shrinkosaurus', '', 'there was young man going to thinland,', 'he had bought two flight tickets to expand,', 'suddenly he had an appetite loss,', 'because adjacent upon hypotenuse is cos,', 'so he joined the scranton band', '', 'shatterstar', '', 'the day you realise', 'happiness is just a state of mind', 'a star falls to remind you', 'nothing lasts forever,', 'kid.', '', 'yet you yearn for yellow youth', 'one last offer to refuse ', 'urges to undo,', 'relive the adieu.', '', 'stand with someone under the shade', 'train today, talk tomorrow', \"always chin up, don't be afraid\", 'regret later, vanquish sorrow', 'seal your own fate.', '', 'to old and the new', '', 'verse i', '', 'chilly winds swept her feet', 'the kid scanned the bus', 'for an empty seat', 'staff only, it said', '', 'feeling out of place,', 'the kid started the chase', 'but the bus is empty, whiskered the kid', 'company policy, said the driver.', '', 'if he takes us, he has to take em all', 'a tail wiggled from under the shawl', 'they walked away from the sun', 'the tail grew in numbers', 'for the tale had just begun.', '', 'verse ii', '', 'for a few feet far', 'a door came ajar', 'come take shelter said the old man', 'came to a halt the ragtag caravan.', '', 'out came the tails ', 'some male, some pale.', 'only one wiggled and stayed', 'others had enough of this charade.', '', 'your grandpa stayed with me', 'after endless quarrels and debris', 'its difficult to let go kiddo', 'you realise things when you are widowed.', '', 'everyone does their job', 'some do it kindly,', 'some always sob.', '', 'the ones who stay ', 'when things go wrong', 'bad things sometimes they might say', 'the thread may break, ', 'love may loose.', 'hang on tight,', 'sing it along.', '', 'verse iii', '', 'the swan song', '', 'letters were written', 'we were bitten', 'to adventures and new places', 'worn out shoe laces', 'tiptoing to the closets', 'magical dimensional pockets', 'we fell in the niagara fall', 'and waltzed over the great wall', 'i wish i knew those were the days', 'the days of old, castles of clay.', '', 'the golden leaf', '', 'as she sang the song,', 'life began to drift apart', 'memories flooded her soul and heart', 'it was time, for her to depart.', '', 'her voice echoed throughout the galaxy', 'an eternal smile, gleaming', 'it was this moment of serenity,', 'a moment when stars are born.', '', \"the cat's tail stood up\", 'like an arrow ', 'aiming at the sky,', 'a golden leaf fell underneath', 'a glistening gamut of goodbye.', '', 'if only tears could fill', 'the void in his little life,', 'a shadow emerged ', 'from a source unknown,', 'the leaf withered', 'into a silent cyclone.', '', 'unfinished business', '', 'the shadow stayed with the kid', 'for years on his back it hid', 'the day came when he fell in love', 'tears fell that day from above', '', 'they went on adventures', 'big and blue', 'mistakes made, broken ties', 'mortal enemies quarreling crew', 'tears again fell', 'not from above', 'but from within', 'their story, fin.', '', 'love was easy,', 'forgiveness is rare', 'trust was real', 'words could repair.', 'now i know why grandma said', 'hang on tight,', \"don't let go kiddo,\", 'someday you will reunite,', 'fight the darkness with light.', '', 'the shadow dissapeared into the night', 'as the star burned beaming bright,', 'he boarded the bus for the final ride.', '', 'merchant of hope', '', 'life passes unnoticed ', 'appreciate inspiring work', 'in words and people', '', 'city of science', '', 'you grow up', 'be it the balloon and cup', '', 'you remember things', 'or the quantum entangled strings', '', 'places of elegance', 'cutouts of scientists of eminence', '', 'places of magic', 'electrifying rides full of static', '', 'the islands of lemurs', 'the city filled with dreamers,', '', 'on a picnic with squirrels and flute,', 'curious cats and paper parachutes.', '', 'a day with turtle', '', 'bathing in sunlight', 'he wishes to see the moon', 'failed attempt at theft', '', 'color block', '', 'pearly white pyjamas', 'doing same old bronze dramas,', 'driving in a canary sedan', 'with hazelnut tan.', '', 'her mahogany stuck lips', 'a feathery rouge mesh hat', 'perishing periwinkle boots beseeching,', \"what's up, teal\", \"haven't seen you in cerulean blue.\", '', 'o, i live in a cave, madam', 'where magic comes to light', 'went a back to black for a while,', 'aged perfectly, with wisdom wine.', '', 'milestogo', '', 'stopped at a milestone', 'looked into the future far', 'retire when ahead', '', 'catgrin on a tin ~', 'scars so deep', 'happy memories asleep', 'promises to keep', 'tears to sweep.', '', 'made you smile', 'made you cry', 'all this while', 'you were dissatified.', '', 'white or grey', \"doesn't matter today\", 'nothing to weigh', 'just walkaway.', '', 'seek to hide', '', 'let the wind blow', 'the echoes away', 'lets plug in the audio', 'and run faraway.', '', \"hiding under ember's glow\", 'burning gently into the night', 'welcome to the jitterbug studio', 'for a discussion erudite', '', 'you may wish to stay', 'or catch a glance', 'you might be lucky today,', 'to win', 'a chance ', 'to finance', 'the romance.', '', 'coincidental accident', '', 'some days we know', 'the signs from universe', 'are not enough.', '', 'but the patterns remain,', 'intricately woven', 'in our beehive minds.', '', 'a name in a movie,', 'a missed call', 'a motif to be drawn.', '', 'retrograding to the time', 'when things made sense', 'the mind was but a pawn', 'infatuated and infected,', 'by fallacies of mortal soul.', '', 'acquaintance in abundance', '', 'i run towards the morning sun', 'only to find headlamps bright', 'posters, oranges, hopes and smiles', 'in abundance i pack.', '', 'where do i live some ask;', 'on a concrete bed with potholes', 'under the north star', 'with a tabby cat with crescent scar', '', 'is this real life some ask;', 'we are what we empthasize with', 'honk, curse, rush and fall', 'all we are but a face, hanging;', 'amidst the bedlam, full of chaos.', '', 'hi, biscus', '', 'chivalry and shrivelry,', 'heroic and stoic,', 'why pluck a new leaf', 'from the tree of life,', 'take an old petal, chief;', 'wrinkled with wisdom,', 'rich with rife.', '', 'end of the line', '', 'every day ends,', 'yet life bills are put on boards.', '', 'hiding in virtual,', 'in reality, we fold.', '', 'life may be on the fast lane,', 'at the end of the tunnel, we need someone to hold.', '', \"it's a bird. \", \"it's a plane.\", \"it's just another blip.\", 'in the skies unknown.', '', 'moving away from merryland', 'into the grey', 'to make mistakes,', 'to fall prey.', '', 'prey to desires,', 'prey to fame,', \"it's a bird,\", 'waiting to become a plane.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhlFHkg4Ie_J",
        "outputId": "10b11524-96b7-484c-c36f-53bb99eefaa7"
      },
      "source": [
        "tokenizer.fit_on_texts(text)\r\n",
        "'''The fit_on_texts method takes one sentence at a time, converts that sentence \r\n",
        "into the number sequence of each word from the dictionary and gives you back the\r\n",
        " final list of sequence.'''\r\n",
        "\r\n",
        "total_words = len(tokenizer.word_index) + 1 # to avoid oov token\r\n",
        "'''total number of words and add the length + 1 just to include a word tag which \r\n",
        "indicates if the new word coming in during testing is in the dictionary or not.'''\r\n",
        "\r\n",
        "print(total_words)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fQFMjX5AiOw"
      },
      "source": [
        "tokenized_text = [] #input vector which we feed the network\r\n",
        "'''The for loop goes sequence by sequence(line by line) and generates new n-gram\r\n",
        " sequences and appends them in our training data.'''\r\n",
        "for line in text:\r\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0] #give text of the sequences for the current line\r\n",
        "\tfor i in range(1, len(token_list)):\r\n",
        "\t\tn_gram_sequence = token_list[:i+1]\r\n",
        "\t\ttokenized_text.append(n_gram_sequence)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXTIznFADo-z"
      },
      "source": [
        "# pad sequences \r\n",
        "max_sequence_len = max([len(item) for item in tokenized_text])\r\n",
        "tokenized_text = np.array(pad_sequences(tokenized_text, maxlen=max_sequence_len, padding='pre'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIo2fiTrDqYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43028bd1-99e1-47af-c852-cb66da5ac908"
      },
      "source": [
        "# create X and y\r\n",
        "X, y = tokenized_text[:,:-1],tokenized_text[:,-1]\r\n",
        "print(X.shape, y.shape)\r\n",
        "#X-> beginning of the list\r\n",
        "#y-> end of the list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3866, 11) (3866,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJfdnBK0vt4F"
      },
      "source": [
        "'''convert targets to categorical y's i.e one hot encode them and treat the\r\n",
        " total number of words in the dictionary as the total number of classes.'''\r\n",
        "y = tensorflow.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPpWh3MuwHcz",
        "outputId": "9a059806-a5cf-4957-b847-c00424ac7464"
      },
      "source": [
        "print(X.shape, y.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3866, 11) (3866, 1674)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGztnQ3OvZyP",
        "outputId": "be9398fa-43aa-45b2-fff1-ae6f7348ad30"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\r\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3092, 11) (774, 11) (3092, 1674) (774, 1674)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqSFwxZ1AOwi"
      },
      "source": [
        "Keras Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju5y27ZpETM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d363a2-2492-4c1c-d01d-aa11b7170494"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHCqrfjEEc3R"
      },
      "source": [
        "import kerastuner"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQzm-YJkVXjd"
      },
      "source": [
        "hp = kerastuner.HyperParameters()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ukB8hE99ENa"
      },
      "source": [
        "def build_model(hp):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\r\n",
        "  model.add(Bidirectional(LSTM(150, return_sequences = True)))\r\n",
        "  model.add(Dropout(0.2))\r\n",
        "  model.add(LSTM(100))\r\n",
        "  #model.add(Bidirectional(LSTM(10, return_sequences = True)))\r\n",
        "  #model.add(Dropout(0.1))\r\n",
        "  #model.add(LSTM(10))\r\n",
        "  '''model.add(Dense(\r\n",
        "      hp.Int('hidden units',\r\n",
        "            min_value=50,\r\n",
        "            max_value = 200,\r\n",
        "            step = 50),\r\n",
        "      activation = 'relu'))'''\r\n",
        "  model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\r\n",
        "  model.add(Dense(total_words, activation='softmax'))\r\n",
        "\r\n",
        "  model.compile(\r\n",
        "    #optimizer=keras.optimizers.SGD(),\r\n",
        "    optimizer='adam',\r\n",
        "    #loss='sparse_categorical_crossentropy',\r\n",
        "    loss='categorical_crossentropy',\r\n",
        "    metrics=['accuracy'])\r\n",
        "  return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAt3GW2D4Xm_"
      },
      "source": [
        "Random Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2F8AxQxAYS_"
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTvEukVHAZ2f"
      },
      "source": [
        "tuner = RandomSearch(\r\n",
        "    build_model,\r\n",
        "    objective='val_accuracy',\r\n",
        "    max_trials=4,\r\n",
        "    executions_per_trial=1,\r\n",
        "    directory='experiments',\r\n",
        "    project_name='test')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v96aAGsDBwKj",
        "outputId": "c211f131-1625-4619-b98a-e9a357dde5b4"
      },
      "source": [
        "tuner.search_space_summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJOdIWUoB88M",
        "outputId": "8eedd086-21bf-4f07-e957-2f200c9b90cd"
      },
      "source": [
        "history = tuner.search(x = X_train, y = y_train, validation_data=(X_test, y_test), epochs = 200)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 24m 20s]\n",
            "val_accuracy: 0.08914728462696075\n",
            "\n",
            "Best val_accuracy So Far: 0.08914728462696075\n",
            "Total elapsed time: 00h 24m 20s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4gcpMKK4PsA",
        "outputId": "3a4ccf7c-a345-4d30-f244-02064c2b0055"
      },
      "source": [
        "tuner.get_best_models(num_models=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f2fb00e25c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLjOVpGG4oZq",
        "outputId": "477e9dae-dd5b-4248-bd00-fd0867c231fd"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in experiments/test\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "default configuration\n",
            "Score: 0.08914728462696075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPx4l9mg665U"
      },
      "source": [
        "BayesianOptimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM_alvNx6qvu"
      },
      "source": [
        "def build_model(hp):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\r\n",
        "  '''the model will take as input an integer matrix of size (batch, input_length). \r\n",
        "  the largest integer (i.e. word index) in the input should be\r\n",
        "  no larger than 999 (vocabulary size). \r\n",
        "  now model.output_shape == (None, 10, 64), where None is the batch dimension.'''\r\n",
        "  model.add(Bidirectional(LSTM(150, return_sequences = True)))\r\n",
        "  model.add(Dropout(0.2)) #to avoid overfitting\r\n",
        "  model.add(LSTM(100))\r\n",
        "  '''model.add(Dense(\r\n",
        "      hp.Int('hidden units',\r\n",
        "            min_value=50,\r\n",
        "            max_value = 200,\r\n",
        "            step = 50),\r\n",
        "      activation = 'relu'))'''\r\n",
        "  model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01))) #regulizer to avoid overfitting\r\n",
        "  # final dense layer => the size of total words to predict\r\n",
        "  model.add(Dense(total_words, activation='softmax'))\r\n",
        "\r\n",
        "  model.compile(\r\n",
        "    optimizer='adam', #with default learnig rate \r\n",
        "    loss='categorical_crossentropy', #our loss function\r\n",
        "    metrics=['accuracy'])\r\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tcdBfNe6yJI"
      },
      "source": [
        "from kerastuner.tuners import BayesianOptimization"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUfrH6GPPTPe"
      },
      "source": [
        "tuner = BayesianOptimization(\r\n",
        "    build_model,\r\n",
        "    objective='val_accuracy',\r\n",
        "    max_trials=5,\r\n",
        "    executions_per_trial=1,\r\n",
        "    directory='experiments',\r\n",
        "    project_name='test2')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUwH7GwF6w5W",
        "outputId": "3fe1f7b9-00c4-4348-a804-90d3efc14f7a"
      },
      "source": [
        "tuner.search_space_summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VyQwINiJfD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310c17bd-bdc5-49c8-9dbc-e9b20c4e365b"
      },
      "source": [
        "history = tuner.search(x = X_train, y = y_train, validation_data=(X_test, y_test), epochs = 10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 01m 17s]\n",
            "val_accuracy: 0.07364340871572495\n",
            "\n",
            "Best val_accuracy So Far: 0.07364340871572495\n",
            "Total elapsed time: 00h 01m 17s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UHtQEo07WN6",
        "outputId": "f5fb88c1-a746-4ac3-d371-d5660abd9930"
      },
      "source": [
        "tuner.get_best_models(num_models=2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f2fb1eca358>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exCp9Jy-PWuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0fc68c-a52a-4819-b8d0-0f99f5be8df6"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in experiments/test2\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "default configuration\n",
            "Score: 0.07364340871572495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWcPi8ve8cE6"
      },
      "source": [
        "'''my_callbacks = [\r\n",
        "    #tf.keras.callbacks.EarlyStopping(patience=2),\r\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\r\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\r\n",
        "]'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8aasevf-EnV"
      },
      "source": [
        "model=build_model(hp)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIY4gr7F-CNa",
        "outputId": "39f565a4-d376-4760-b6e6-6a2dafea3595"
      },
      "source": [
        "#history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 200, callbacks=my_callbacks)\r\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 300)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "97/97 [==============================] - 13s 83ms/step - loss: 8.0331 - accuracy: 0.0415 - val_loss: 6.8715 - val_accuracy: 0.0659\n",
            "Epoch 2/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 6.5113 - accuracy: 0.0593 - val_loss: 6.8948 - val_accuracy: 0.0646\n",
            "Epoch 3/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 6.4054 - accuracy: 0.0480 - val_loss: 7.0227 - val_accuracy: 0.0659\n",
            "Epoch 4/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 6.1890 - accuracy: 0.0555 - val_loss: 7.2354 - val_accuracy: 0.0659\n",
            "Epoch 5/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 6.0767 - accuracy: 0.0569 - val_loss: 7.2479 - val_accuracy: 0.0659\n",
            "Epoch 6/300\n",
            "97/97 [==============================] - 7s 71ms/step - loss: 5.9834 - accuracy: 0.0558 - val_loss: 7.3600 - val_accuracy: 0.0659\n",
            "Epoch 7/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.9332 - accuracy: 0.0544 - val_loss: 7.3781 - val_accuracy: 0.0724\n",
            "Epoch 8/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.8511 - accuracy: 0.0494 - val_loss: 7.5022 - val_accuracy: 0.0659\n",
            "Epoch 9/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.8043 - accuracy: 0.0639 - val_loss: 7.7792 - val_accuracy: 0.0698\n",
            "Epoch 10/300\n",
            "97/97 [==============================] - 7s 71ms/step - loss: 5.8184 - accuracy: 0.0500 - val_loss: 7.6576 - val_accuracy: 0.0698\n",
            "Epoch 11/300\n",
            "97/97 [==============================] - 7s 70ms/step - loss: 5.7424 - accuracy: 0.0572 - val_loss: 7.5745 - val_accuracy: 0.0749\n",
            "Epoch 12/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.7010 - accuracy: 0.0571 - val_loss: 7.6510 - val_accuracy: 0.0749\n",
            "Epoch 13/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 5.5487 - accuracy: 0.0651 - val_loss: 7.7481 - val_accuracy: 0.0762\n",
            "Epoch 14/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.6350 - accuracy: 0.0593 - val_loss: 7.9440 - val_accuracy: 0.0659\n",
            "Epoch 15/300\n",
            "97/97 [==============================] - 7s 71ms/step - loss: 5.6334 - accuracy: 0.0567 - val_loss: 8.2114 - val_accuracy: 0.0659\n",
            "Epoch 16/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.5056 - accuracy: 0.0528 - val_loss: 8.1292 - val_accuracy: 0.0672\n",
            "Epoch 17/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 5.4812 - accuracy: 0.0589 - val_loss: 8.2764 - val_accuracy: 0.0659\n",
            "Epoch 18/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 5.5003 - accuracy: 0.0626 - val_loss: 8.2838 - val_accuracy: 0.0698\n",
            "Epoch 19/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.5430 - accuracy: 0.0540 - val_loss: 8.4769 - val_accuracy: 0.0633\n",
            "Epoch 20/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.4787 - accuracy: 0.0561 - val_loss: 8.4571 - val_accuracy: 0.0620\n",
            "Epoch 21/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 5.4552 - accuracy: 0.0646 - val_loss: 8.5121 - val_accuracy: 0.0568\n",
            "Epoch 22/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 5.4118 - accuracy: 0.0620 - val_loss: 8.5390 - val_accuracy: 0.0568\n",
            "Epoch 23/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.3563 - accuracy: 0.0631 - val_loss: 8.5864 - val_accuracy: 0.0581\n",
            "Epoch 24/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 5.3263 - accuracy: 0.0585 - val_loss: 8.6324 - val_accuracy: 0.0543\n",
            "Epoch 25/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 5.3211 - accuracy: 0.0670 - val_loss: 8.7041 - val_accuracy: 0.0581\n",
            "Epoch 26/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 5.3377 - accuracy: 0.0631 - val_loss: 7.8355 - val_accuracy: 0.0659\n",
            "Epoch 27/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 5.7170 - accuracy: 0.0535 - val_loss: 8.7509 - val_accuracy: 0.0646\n",
            "Epoch 28/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 5.3805 - accuracy: 0.0506 - val_loss: 8.9440 - val_accuracy: 0.0633\n",
            "Epoch 29/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.2190 - accuracy: 0.0653 - val_loss: 8.9627 - val_accuracy: 0.0607\n",
            "Epoch 30/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 5.2370 - accuracy: 0.0677 - val_loss: 9.1665 - val_accuracy: 0.0659\n",
            "Epoch 31/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.1233 - accuracy: 0.0660 - val_loss: 9.3201 - val_accuracy: 0.0711\n",
            "Epoch 32/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.0912 - accuracy: 0.0774 - val_loss: 9.4223 - val_accuracy: 0.0724\n",
            "Epoch 33/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 5.0771 - accuracy: 0.0698 - val_loss: 9.6116 - val_accuracy: 0.0633\n",
            "Epoch 34/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.9929 - accuracy: 0.0789 - val_loss: 9.7329 - val_accuracy: 0.0568\n",
            "Epoch 35/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.9773 - accuracy: 0.0645 - val_loss: 9.9171 - val_accuracy: 0.0646\n",
            "Epoch 36/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.9339 - accuracy: 0.0713 - val_loss: 9.9886 - val_accuracy: 0.0698\n",
            "Epoch 37/300\n",
            "97/97 [==============================] - 7s 71ms/step - loss: 4.9109 - accuracy: 0.0791 - val_loss: 10.3253 - val_accuracy: 0.0659\n",
            "Epoch 38/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 4.8210 - accuracy: 0.0820 - val_loss: 10.5406 - val_accuracy: 0.0633\n",
            "Epoch 39/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 4.7386 - accuracy: 0.0792 - val_loss: 10.5590 - val_accuracy: 0.0646\n",
            "Epoch 40/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 4.7092 - accuracy: 0.0897 - val_loss: 10.7826 - val_accuracy: 0.0581\n",
            "Epoch 41/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.6992 - accuracy: 0.0932 - val_loss: 11.1147 - val_accuracy: 0.0646\n",
            "Epoch 42/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.6236 - accuracy: 0.0899 - val_loss: 11.1229 - val_accuracy: 0.0633\n",
            "Epoch 43/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.6007 - accuracy: 0.1054 - val_loss: 11.0990 - val_accuracy: 0.0620\n",
            "Epoch 44/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.5767 - accuracy: 0.0970 - val_loss: 11.5274 - val_accuracy: 0.0543\n",
            "Epoch 45/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.4885 - accuracy: 0.1064 - val_loss: 11.6092 - val_accuracy: 0.0594\n",
            "Epoch 46/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.4441 - accuracy: 0.1123 - val_loss: 11.6165 - val_accuracy: 0.0594\n",
            "Epoch 47/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 4.4235 - accuracy: 0.1084 - val_loss: 11.9400 - val_accuracy: 0.0530\n",
            "Epoch 48/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.4281 - accuracy: 0.1118 - val_loss: 11.8087 - val_accuracy: 0.0556\n",
            "Epoch 49/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.4263 - accuracy: 0.0990 - val_loss: 12.1259 - val_accuracy: 0.0581\n",
            "Epoch 50/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.3191 - accuracy: 0.1184 - val_loss: 12.2077 - val_accuracy: 0.0594\n",
            "Epoch 51/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.2130 - accuracy: 0.1376 - val_loss: 12.3382 - val_accuracy: 0.0594\n",
            "Epoch 52/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.2174 - accuracy: 0.1175 - val_loss: 12.4743 - val_accuracy: 0.0426\n",
            "Epoch 53/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.1365 - accuracy: 0.1375 - val_loss: 12.7161 - val_accuracy: 0.0594\n",
            "Epoch 54/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.1242 - accuracy: 0.1259 - val_loss: 12.9372 - val_accuracy: 0.0556\n",
            "Epoch 55/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 4.0827 - accuracy: 0.1371 - val_loss: 13.0258 - val_accuracy: 0.0491\n",
            "Epoch 56/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.0547 - accuracy: 0.1345 - val_loss: 13.1824 - val_accuracy: 0.0530\n",
            "Epoch 57/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 4.0449 - accuracy: 0.1457 - val_loss: 13.2417 - val_accuracy: 0.0543\n",
            "Epoch 58/300\n",
            "97/97 [==============================] - 7s 71ms/step - loss: 3.9352 - accuracy: 0.1595 - val_loss: 13.3874 - val_accuracy: 0.0543\n",
            "Epoch 59/300\n",
            "97/97 [==============================] - 7s 71ms/step - loss: 3.9361 - accuracy: 0.1565 - val_loss: 13.5457 - val_accuracy: 0.0530\n",
            "Epoch 60/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 3.8624 - accuracy: 0.1555 - val_loss: 13.7984 - val_accuracy: 0.0568\n",
            "Epoch 61/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 3.8311 - accuracy: 0.1539 - val_loss: 13.8546 - val_accuracy: 0.0620\n",
            "Epoch 62/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.7792 - accuracy: 0.1813 - val_loss: 13.9633 - val_accuracy: 0.0504\n",
            "Epoch 63/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.7735 - accuracy: 0.1737 - val_loss: 14.1031 - val_accuracy: 0.0504\n",
            "Epoch 64/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.7205 - accuracy: 0.1837 - val_loss: 14.2585 - val_accuracy: 0.0491\n",
            "Epoch 65/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.7112 - accuracy: 0.1844 - val_loss: 14.2941 - val_accuracy: 0.0413\n",
            "Epoch 66/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.6526 - accuracy: 0.2144 - val_loss: 14.5595 - val_accuracy: 0.0543\n",
            "Epoch 67/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.5481 - accuracy: 0.2147 - val_loss: 14.6507 - val_accuracy: 0.0646\n",
            "Epoch 68/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.5644 - accuracy: 0.2076 - val_loss: 14.7284 - val_accuracy: 0.0517\n",
            "Epoch 69/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.5847 - accuracy: 0.2046 - val_loss: 14.7393 - val_accuracy: 0.0491\n",
            "Epoch 70/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 3.5183 - accuracy: 0.2275 - val_loss: 14.9796 - val_accuracy: 0.0530\n",
            "Epoch 71/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.4555 - accuracy: 0.2166 - val_loss: 14.9924 - val_accuracy: 0.0465\n",
            "Epoch 72/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.4018 - accuracy: 0.2234 - val_loss: 15.1521 - val_accuracy: 0.0491\n",
            "Epoch 73/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.3709 - accuracy: 0.2448 - val_loss: 15.2712 - val_accuracy: 0.0517\n",
            "Epoch 74/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.3231 - accuracy: 0.2560 - val_loss: 15.2995 - val_accuracy: 0.0517\n",
            "Epoch 75/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.3426 - accuracy: 0.2577 - val_loss: 15.4387 - val_accuracy: 0.0568\n",
            "Epoch 76/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.2560 - accuracy: 0.2806 - val_loss: 15.5637 - val_accuracy: 0.0543\n",
            "Epoch 77/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 3.2843 - accuracy: 0.2787 - val_loss: 15.6410 - val_accuracy: 0.0517\n",
            "Epoch 78/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 3.2070 - accuracy: 0.2779 - val_loss: 15.6707 - val_accuracy: 0.0491\n",
            "Epoch 79/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.1873 - accuracy: 0.2848 - val_loss: 15.7692 - val_accuracy: 0.0581\n",
            "Epoch 80/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 3.1151 - accuracy: 0.3080 - val_loss: 15.9377 - val_accuracy: 0.0556\n",
            "Epoch 81/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 3.1167 - accuracy: 0.3112 - val_loss: 16.0499 - val_accuracy: 0.0556\n",
            "Epoch 82/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.1384 - accuracy: 0.3049 - val_loss: 16.0878 - val_accuracy: 0.0517\n",
            "Epoch 83/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 3.0333 - accuracy: 0.3336 - val_loss: 16.0851 - val_accuracy: 0.0530\n",
            "Epoch 84/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 3.0452 - accuracy: 0.3400 - val_loss: 16.2498 - val_accuracy: 0.0594\n",
            "Epoch 85/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 3.0037 - accuracy: 0.3470 - val_loss: 16.3582 - val_accuracy: 0.0568\n",
            "Epoch 86/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.9379 - accuracy: 0.3597 - val_loss: 16.4449 - val_accuracy: 0.0556\n",
            "Epoch 87/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.8865 - accuracy: 0.3758 - val_loss: 16.5458 - val_accuracy: 0.0581\n",
            "Epoch 88/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 2.8603 - accuracy: 0.3760 - val_loss: 16.5464 - val_accuracy: 0.0581\n",
            "Epoch 89/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 2.8506 - accuracy: 0.3911 - val_loss: 16.6951 - val_accuracy: 0.0543\n",
            "Epoch 90/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 2.7806 - accuracy: 0.4055 - val_loss: 16.8742 - val_accuracy: 0.0568\n",
            "Epoch 91/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 2.8143 - accuracy: 0.4029 - val_loss: 16.6702 - val_accuracy: 0.0581\n",
            "Epoch 92/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 2.7403 - accuracy: 0.4251 - val_loss: 16.8410 - val_accuracy: 0.0543\n",
            "Epoch 93/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 2.7649 - accuracy: 0.4235 - val_loss: 16.9854 - val_accuracy: 0.0581\n",
            "Epoch 94/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 2.7801 - accuracy: 0.4148 - val_loss: 17.0224 - val_accuracy: 0.0568\n",
            "Epoch 95/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 2.7190 - accuracy: 0.4281 - val_loss: 17.1543 - val_accuracy: 0.0646\n",
            "Epoch 96/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 2.6094 - accuracy: 0.4472 - val_loss: 17.2018 - val_accuracy: 0.0620\n",
            "Epoch 97/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.5376 - accuracy: 0.4718 - val_loss: 17.1212 - val_accuracy: 0.0633\n",
            "Epoch 98/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.6034 - accuracy: 0.4556 - val_loss: 17.2309 - val_accuracy: 0.0659\n",
            "Epoch 99/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.5526 - accuracy: 0.4650 - val_loss: 17.4141 - val_accuracy: 0.0581\n",
            "Epoch 100/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.5490 - accuracy: 0.4827 - val_loss: 17.4267 - val_accuracy: 0.0620\n",
            "Epoch 101/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.4673 - accuracy: 0.5006 - val_loss: 17.4370 - val_accuracy: 0.0620\n",
            "Epoch 102/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.4315 - accuracy: 0.4986 - val_loss: 17.5292 - val_accuracy: 0.0646\n",
            "Epoch 103/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.4354 - accuracy: 0.4964 - val_loss: 17.5354 - val_accuracy: 0.0568\n",
            "Epoch 104/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.4297 - accuracy: 0.5069 - val_loss: 17.6759 - val_accuracy: 0.0556\n",
            "Epoch 105/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.4611 - accuracy: 0.4924 - val_loss: 17.6608 - val_accuracy: 0.0568\n",
            "Epoch 106/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.3543 - accuracy: 0.5228 - val_loss: 17.7209 - val_accuracy: 0.0646\n",
            "Epoch 107/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.3422 - accuracy: 0.5240 - val_loss: 17.7929 - val_accuracy: 0.0620\n",
            "Epoch 108/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 2.3541 - accuracy: 0.5245 - val_loss: 17.7562 - val_accuracy: 0.0568\n",
            "Epoch 109/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 2.3197 - accuracy: 0.5342 - val_loss: 17.9525 - val_accuracy: 0.0568\n",
            "Epoch 110/300\n",
            "97/97 [==============================] - 7s 72ms/step - loss: 2.2995 - accuracy: 0.5395 - val_loss: 18.0030 - val_accuracy: 0.0620\n",
            "Epoch 111/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 2.2513 - accuracy: 0.5522 - val_loss: 17.9135 - val_accuracy: 0.0620\n",
            "Epoch 112/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.2914 - accuracy: 0.5404 - val_loss: 17.8417 - val_accuracy: 0.0659\n",
            "Epoch 113/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.2532 - accuracy: 0.5560 - val_loss: 18.0653 - val_accuracy: 0.0620\n",
            "Epoch 114/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 2.2364 - accuracy: 0.5553 - val_loss: 18.0672 - val_accuracy: 0.0620\n",
            "Epoch 115/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.1888 - accuracy: 0.5642 - val_loss: 18.2025 - val_accuracy: 0.0620\n",
            "Epoch 116/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.1650 - accuracy: 0.5718 - val_loss: 18.0870 - val_accuracy: 0.0607\n",
            "Epoch 117/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 2.1546 - accuracy: 0.5944 - val_loss: 18.1620 - val_accuracy: 0.0620\n",
            "Epoch 118/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.1541 - accuracy: 0.5774 - val_loss: 18.0317 - val_accuracy: 0.0672\n",
            "Epoch 119/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.1429 - accuracy: 0.5743 - val_loss: 17.9663 - val_accuracy: 0.0659\n",
            "Epoch 120/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.0823 - accuracy: 0.5884 - val_loss: 18.1800 - val_accuracy: 0.0659\n",
            "Epoch 121/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.0068 - accuracy: 0.6223 - val_loss: 18.1984 - val_accuracy: 0.0568\n",
            "Epoch 122/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 2.0659 - accuracy: 0.6026 - val_loss: 18.2052 - val_accuracy: 0.0646\n",
            "Epoch 123/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.9601 - accuracy: 0.6303 - val_loss: 18.1838 - val_accuracy: 0.0581\n",
            "Epoch 124/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 2.0063 - accuracy: 0.6284 - val_loss: 18.2217 - val_accuracy: 0.0556\n",
            "Epoch 125/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.9748 - accuracy: 0.6134 - val_loss: 18.2473 - val_accuracy: 0.0698\n",
            "Epoch 126/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.9470 - accuracy: 0.6183 - val_loss: 18.3653 - val_accuracy: 0.0698\n",
            "Epoch 127/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.9020 - accuracy: 0.6453 - val_loss: 18.2435 - val_accuracy: 0.0581\n",
            "Epoch 128/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 1.9352 - accuracy: 0.6354 - val_loss: 18.4534 - val_accuracy: 0.0543\n",
            "Epoch 129/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.8863 - accuracy: 0.6441 - val_loss: 18.4152 - val_accuracy: 0.0594\n",
            "Epoch 130/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.8922 - accuracy: 0.6517 - val_loss: 18.4645 - val_accuracy: 0.0646\n",
            "Epoch 131/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.8562 - accuracy: 0.6517 - val_loss: 18.4012 - val_accuracy: 0.0581\n",
            "Epoch 132/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.8852 - accuracy: 0.6465 - val_loss: 18.3861 - val_accuracy: 0.0646\n",
            "Epoch 133/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.8516 - accuracy: 0.6584 - val_loss: 18.5958 - val_accuracy: 0.0646\n",
            "Epoch 134/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.8063 - accuracy: 0.6713 - val_loss: 18.5061 - val_accuracy: 0.0607\n",
            "Epoch 135/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.8223 - accuracy: 0.6666 - val_loss: 18.5426 - val_accuracy: 0.0568\n",
            "Epoch 136/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.7896 - accuracy: 0.6748 - val_loss: 18.6721 - val_accuracy: 0.0607\n",
            "Epoch 137/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.8007 - accuracy: 0.6582 - val_loss: 18.5606 - val_accuracy: 0.0659\n",
            "Epoch 138/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.7739 - accuracy: 0.6784 - val_loss: 18.4349 - val_accuracy: 0.0685\n",
            "Epoch 139/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.7638 - accuracy: 0.6839 - val_loss: 18.6382 - val_accuracy: 0.0581\n",
            "Epoch 140/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.7627 - accuracy: 0.6825 - val_loss: 18.5629 - val_accuracy: 0.0581\n",
            "Epoch 141/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.7155 - accuracy: 0.6824 - val_loss: 18.5777 - val_accuracy: 0.0659\n",
            "Epoch 142/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.7859 - accuracy: 0.6787 - val_loss: 18.4649 - val_accuracy: 0.0659\n",
            "Epoch 143/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.7275 - accuracy: 0.6742 - val_loss: 18.5019 - val_accuracy: 0.0568\n",
            "Epoch 144/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.7455 - accuracy: 0.6804 - val_loss: 18.6498 - val_accuracy: 0.0581\n",
            "Epoch 145/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.6780 - accuracy: 0.6977 - val_loss: 18.5556 - val_accuracy: 0.0672\n",
            "Epoch 146/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.6457 - accuracy: 0.7072 - val_loss: 18.6448 - val_accuracy: 0.0568\n",
            "Epoch 147/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.6564 - accuracy: 0.6928 - val_loss: 18.7037 - val_accuracy: 0.0646\n",
            "Epoch 148/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.6030 - accuracy: 0.7179 - val_loss: 18.6123 - val_accuracy: 0.0607\n",
            "Epoch 149/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.5895 - accuracy: 0.7126 - val_loss: 18.8292 - val_accuracy: 0.0659\n",
            "Epoch 150/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.5842 - accuracy: 0.7185 - val_loss: 18.6056 - val_accuracy: 0.0568\n",
            "Epoch 151/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.5697 - accuracy: 0.7181 - val_loss: 18.7152 - val_accuracy: 0.0685\n",
            "Epoch 152/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.5478 - accuracy: 0.7251 - val_loss: 18.8132 - val_accuracy: 0.0568\n",
            "Epoch 153/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.5436 - accuracy: 0.7303 - val_loss: 18.7283 - val_accuracy: 0.0581\n",
            "Epoch 154/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.5673 - accuracy: 0.7221 - val_loss: 18.7495 - val_accuracy: 0.0685\n",
            "Epoch 155/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.5306 - accuracy: 0.7179 - val_loss: 18.7882 - val_accuracy: 0.0685\n",
            "Epoch 156/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.5630 - accuracy: 0.7213 - val_loss: 18.6993 - val_accuracy: 0.0646\n",
            "Epoch 157/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.4939 - accuracy: 0.7353 - val_loss: 18.6784 - val_accuracy: 0.0581\n",
            "Epoch 158/300\n",
            "97/97 [==============================] - 7s 73ms/step - loss: 1.5495 - accuracy: 0.7194 - val_loss: 18.7196 - val_accuracy: 0.0659\n",
            "Epoch 159/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.5060 - accuracy: 0.7294 - val_loss: 18.7028 - val_accuracy: 0.0633\n",
            "Epoch 160/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.4408 - accuracy: 0.7448 - val_loss: 18.6277 - val_accuracy: 0.0594\n",
            "Epoch 161/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.4457 - accuracy: 0.7528 - val_loss: 18.6907 - val_accuracy: 0.0581\n",
            "Epoch 162/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.4472 - accuracy: 0.7469 - val_loss: 18.8611 - val_accuracy: 0.0568\n",
            "Epoch 163/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.4320 - accuracy: 0.7463 - val_loss: 18.6949 - val_accuracy: 0.0646\n",
            "Epoch 164/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.4644 - accuracy: 0.7346 - val_loss: 18.6948 - val_accuracy: 0.0659\n",
            "Epoch 165/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.5064 - accuracy: 0.7241 - val_loss: 18.6237 - val_accuracy: 0.0620\n",
            "Epoch 166/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.4543 - accuracy: 0.7408 - val_loss: 18.6851 - val_accuracy: 0.0646\n",
            "Epoch 167/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.4878 - accuracy: 0.7241 - val_loss: 18.6379 - val_accuracy: 0.0543\n",
            "Epoch 168/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.4246 - accuracy: 0.7439 - val_loss: 18.7159 - val_accuracy: 0.0607\n",
            "Epoch 169/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.4311 - accuracy: 0.7430 - val_loss: 18.5937 - val_accuracy: 0.0633\n",
            "Epoch 170/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.3592 - accuracy: 0.7610 - val_loss: 18.6883 - val_accuracy: 0.0633\n",
            "Epoch 171/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.3811 - accuracy: 0.7548 - val_loss: 18.6745 - val_accuracy: 0.0594\n",
            "Epoch 172/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.3720 - accuracy: 0.7494 - val_loss: 18.8458 - val_accuracy: 0.0568\n",
            "Epoch 173/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.3556 - accuracy: 0.7643 - val_loss: 18.7602 - val_accuracy: 0.0530\n",
            "Epoch 174/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.3479 - accuracy: 0.7653 - val_loss: 18.6223 - val_accuracy: 0.0581\n",
            "Epoch 175/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.3581 - accuracy: 0.7622 - val_loss: 18.6801 - val_accuracy: 0.0594\n",
            "Epoch 176/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.3383 - accuracy: 0.7612 - val_loss: 18.7132 - val_accuracy: 0.0556\n",
            "Epoch 177/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.3246 - accuracy: 0.7649 - val_loss: 18.5129 - val_accuracy: 0.0633\n",
            "Epoch 178/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2587 - accuracy: 0.7828 - val_loss: 18.6710 - val_accuracy: 0.0607\n",
            "Epoch 179/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.2691 - accuracy: 0.7707 - val_loss: 18.6414 - val_accuracy: 0.0685\n",
            "Epoch 180/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.3103 - accuracy: 0.7782 - val_loss: 18.6635 - val_accuracy: 0.0672\n",
            "Epoch 181/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.2955 - accuracy: 0.7649 - val_loss: 18.6298 - val_accuracy: 0.0581\n",
            "Epoch 182/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.2649 - accuracy: 0.7737 - val_loss: 18.7445 - val_accuracy: 0.0581\n",
            "Epoch 183/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.2783 - accuracy: 0.7713 - val_loss: 18.6161 - val_accuracy: 0.0581\n",
            "Epoch 184/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2477 - accuracy: 0.7752 - val_loss: 18.5786 - val_accuracy: 0.0672\n",
            "Epoch 185/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.2701 - accuracy: 0.7655 - val_loss: 18.5624 - val_accuracy: 0.0543\n",
            "Epoch 186/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2991 - accuracy: 0.7629 - val_loss: 18.8612 - val_accuracy: 0.0607\n",
            "Epoch 187/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 1.2303 - accuracy: 0.7902 - val_loss: 18.5280 - val_accuracy: 0.0568\n",
            "Epoch 188/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.2142 - accuracy: 0.7887 - val_loss: 18.6615 - val_accuracy: 0.0672\n",
            "Epoch 189/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2223 - accuracy: 0.7900 - val_loss: 18.5734 - val_accuracy: 0.0672\n",
            "Epoch 190/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2306 - accuracy: 0.7780 - val_loss: 18.6702 - val_accuracy: 0.0672\n",
            "Epoch 191/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.1873 - accuracy: 0.7938 - val_loss: 18.6088 - val_accuracy: 0.0646\n",
            "Epoch 192/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.2031 - accuracy: 0.7818 - val_loss: 18.6422 - val_accuracy: 0.0646\n",
            "Epoch 193/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2063 - accuracy: 0.7811 - val_loss: 18.6368 - val_accuracy: 0.0633\n",
            "Epoch 194/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.1686 - accuracy: 0.7978 - val_loss: 18.6029 - val_accuracy: 0.0620\n",
            "Epoch 195/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.1839 - accuracy: 0.7867 - val_loss: 18.5183 - val_accuracy: 0.0672\n",
            "Epoch 196/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.1577 - accuracy: 0.8036 - val_loss: 18.5696 - val_accuracy: 0.0620\n",
            "Epoch 197/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.2011 - accuracy: 0.7864 - val_loss: 18.6610 - val_accuracy: 0.0607\n",
            "Epoch 198/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.1570 - accuracy: 0.7951 - val_loss: 18.6486 - val_accuracy: 0.0620\n",
            "Epoch 199/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.1348 - accuracy: 0.7931 - val_loss: 18.7573 - val_accuracy: 0.0607\n",
            "Epoch 200/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.2047 - accuracy: 0.7688 - val_loss: 18.5571 - val_accuracy: 0.0646\n",
            "Epoch 201/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.1511 - accuracy: 0.7936 - val_loss: 18.6913 - val_accuracy: 0.0607\n",
            "Epoch 202/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.1085 - accuracy: 0.8013 - val_loss: 18.4787 - val_accuracy: 0.0620\n",
            "Epoch 203/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.2185 - accuracy: 0.7785 - val_loss: 18.5620 - val_accuracy: 0.0620\n",
            "Epoch 204/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.1638 - accuracy: 0.7831 - val_loss: 18.5298 - val_accuracy: 0.0620\n",
            "Epoch 205/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.1390 - accuracy: 0.7934 - val_loss: 18.4746 - val_accuracy: 0.0711\n",
            "Epoch 206/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.0701 - accuracy: 0.8037 - val_loss: 18.6317 - val_accuracy: 0.0607\n",
            "Epoch 207/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.0557 - accuracy: 0.8092 - val_loss: 18.5707 - val_accuracy: 0.0607\n",
            "Epoch 208/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0969 - accuracy: 0.8086 - val_loss: 18.6213 - val_accuracy: 0.0620\n",
            "Epoch 209/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0972 - accuracy: 0.7984 - val_loss: 18.6123 - val_accuracy: 0.0659\n",
            "Epoch 210/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0754 - accuracy: 0.8002 - val_loss: 18.5430 - val_accuracy: 0.0659\n",
            "Epoch 211/300\n",
            "97/97 [==============================] - 8s 80ms/step - loss: 1.0775 - accuracy: 0.7940 - val_loss: 18.4890 - val_accuracy: 0.0633\n",
            "Epoch 212/300\n",
            "97/97 [==============================] - 8s 81ms/step - loss: 1.0622 - accuracy: 0.8037 - val_loss: 18.5739 - val_accuracy: 0.0672\n",
            "Epoch 213/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0482 - accuracy: 0.8179 - val_loss: 18.6581 - val_accuracy: 0.0685\n",
            "Epoch 214/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0685 - accuracy: 0.8031 - val_loss: 18.5981 - val_accuracy: 0.0607\n",
            "Epoch 215/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0771 - accuracy: 0.7999 - val_loss: 18.5496 - val_accuracy: 0.0594\n",
            "Epoch 216/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0565 - accuracy: 0.8049 - val_loss: 18.4267 - val_accuracy: 0.0607\n",
            "Epoch 217/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.0010 - accuracy: 0.8126 - val_loss: 18.6013 - val_accuracy: 0.0607\n",
            "Epoch 218/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.0314 - accuracy: 0.8203 - val_loss: 18.4483 - val_accuracy: 0.0607\n",
            "Epoch 219/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.0966 - accuracy: 0.7898 - val_loss: 18.4309 - val_accuracy: 0.0607\n",
            "Epoch 220/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.1658 - accuracy: 0.7731 - val_loss: 18.5033 - val_accuracy: 0.0568\n",
            "Epoch 221/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.1336 - accuracy: 0.7830 - val_loss: 18.4267 - val_accuracy: 0.0749\n",
            "Epoch 222/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0549 - accuracy: 0.7963 - val_loss: 18.5854 - val_accuracy: 0.0736\n",
            "Epoch 223/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 1.0683 - accuracy: 0.7901 - val_loss: 18.6538 - val_accuracy: 0.0594\n",
            "Epoch 224/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.0092 - accuracy: 0.8086 - val_loss: 18.5334 - val_accuracy: 0.0698\n",
            "Epoch 225/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.0325 - accuracy: 0.8006 - val_loss: 18.5378 - val_accuracy: 0.0568\n",
            "Epoch 226/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 1.0265 - accuracy: 0.8085 - val_loss: 18.4423 - val_accuracy: 0.0633\n",
            "Epoch 227/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9977 - accuracy: 0.8059 - val_loss: 18.5856 - val_accuracy: 0.0659\n",
            "Epoch 228/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9881 - accuracy: 0.8108 - val_loss: 18.3777 - val_accuracy: 0.0775\n",
            "Epoch 229/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9610 - accuracy: 0.8154 - val_loss: 18.5864 - val_accuracy: 0.0646\n",
            "Epoch 230/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9646 - accuracy: 0.8135 - val_loss: 18.3963 - val_accuracy: 0.0659\n",
            "Epoch 231/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9553 - accuracy: 0.8160 - val_loss: 18.2908 - val_accuracy: 0.0672\n",
            "Epoch 232/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9293 - accuracy: 0.8251 - val_loss: 18.3518 - val_accuracy: 0.0672\n",
            "Epoch 233/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9645 - accuracy: 0.8186 - val_loss: 18.4216 - val_accuracy: 0.0633\n",
            "Epoch 234/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9724 - accuracy: 0.8067 - val_loss: 18.4141 - val_accuracy: 0.0594\n",
            "Epoch 235/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.0050 - accuracy: 0.8078 - val_loss: 18.4955 - val_accuracy: 0.0568\n",
            "Epoch 236/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 1.0186 - accuracy: 0.8052 - val_loss: 18.4779 - val_accuracy: 0.0633\n",
            "Epoch 237/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9776 - accuracy: 0.8068 - val_loss: 18.3935 - val_accuracy: 0.0633\n",
            "Epoch 238/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 1.0255 - accuracy: 0.7966 - val_loss: 18.2705 - val_accuracy: 0.0633\n",
            "Epoch 239/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9758 - accuracy: 0.8127 - val_loss: 18.4700 - val_accuracy: 0.0594\n",
            "Epoch 240/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9773 - accuracy: 0.8074 - val_loss: 18.3559 - val_accuracy: 0.0633\n",
            "Epoch 241/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9538 - accuracy: 0.8090 - val_loss: 18.4640 - val_accuracy: 0.0685\n",
            "Epoch 242/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9820 - accuracy: 0.8080 - val_loss: 18.3454 - val_accuracy: 0.0607\n",
            "Epoch 243/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8928 - accuracy: 0.8273 - val_loss: 18.2766 - val_accuracy: 0.0672\n",
            "Epoch 244/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9552 - accuracy: 0.8078 - val_loss: 18.3847 - val_accuracy: 0.0724\n",
            "Epoch 245/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9433 - accuracy: 0.8106 - val_loss: 18.4365 - val_accuracy: 0.0620\n",
            "Epoch 246/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9488 - accuracy: 0.8117 - val_loss: 18.3231 - val_accuracy: 0.0685\n",
            "Epoch 247/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9380 - accuracy: 0.8103 - val_loss: 18.2122 - val_accuracy: 0.0698\n",
            "Epoch 248/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.9707 - accuracy: 0.8042 - val_loss: 18.3296 - val_accuracy: 0.0672\n",
            "Epoch 249/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9173 - accuracy: 0.8226 - val_loss: 18.2577 - val_accuracy: 0.0736\n",
            "Epoch 250/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9594 - accuracy: 0.8172 - val_loss: 18.4532 - val_accuracy: 0.0607\n",
            "Epoch 251/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9562 - accuracy: 0.8103 - val_loss: 18.3552 - val_accuracy: 0.0646\n",
            "Epoch 252/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9448 - accuracy: 0.8056 - val_loss: 18.3878 - val_accuracy: 0.0672\n",
            "Epoch 253/300\n",
            "97/97 [==============================] - 8s 82ms/step - loss: 0.9244 - accuracy: 0.8104 - val_loss: 18.4239 - val_accuracy: 0.0633\n",
            "Epoch 254/300\n",
            "97/97 [==============================] - 8s 77ms/step - loss: 0.9147 - accuracy: 0.8089 - val_loss: 18.3654 - val_accuracy: 0.0698\n",
            "Epoch 255/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9235 - accuracy: 0.8072 - val_loss: 18.1722 - val_accuracy: 0.0620\n",
            "Epoch 256/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9118 - accuracy: 0.8103 - val_loss: 18.3868 - val_accuracy: 0.0594\n",
            "Epoch 257/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8882 - accuracy: 0.8211 - val_loss: 18.4609 - val_accuracy: 0.0672\n",
            "Epoch 258/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8932 - accuracy: 0.8239 - val_loss: 18.2396 - val_accuracy: 0.0698\n",
            "Epoch 259/300\n",
            "97/97 [==============================] - 8s 79ms/step - loss: 0.9132 - accuracy: 0.8131 - val_loss: 18.4926 - val_accuracy: 0.0646\n",
            "Epoch 260/300\n",
            "97/97 [==============================] - 8s 82ms/step - loss: 0.9433 - accuracy: 0.7980 - val_loss: 18.4178 - val_accuracy: 0.0568\n",
            "Epoch 261/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9451 - accuracy: 0.8091 - val_loss: 18.3813 - val_accuracy: 0.0698\n",
            "Epoch 262/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.9302 - accuracy: 0.8099 - val_loss: 18.3894 - val_accuracy: 0.0633\n",
            "Epoch 263/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8444 - accuracy: 0.8347 - val_loss: 18.3454 - val_accuracy: 0.0672\n",
            "Epoch 264/300\n",
            "97/97 [==============================] - 7s 74ms/step - loss: 0.9016 - accuracy: 0.8072 - val_loss: 18.2001 - val_accuracy: 0.0724\n",
            "Epoch 265/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8462 - accuracy: 0.8221 - val_loss: 18.2676 - val_accuracy: 0.0594\n",
            "Epoch 266/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8779 - accuracy: 0.8197 - val_loss: 18.2878 - val_accuracy: 0.0620\n",
            "Epoch 267/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8635 - accuracy: 0.8277 - val_loss: 18.0730 - val_accuracy: 0.0633\n",
            "Epoch 268/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8472 - accuracy: 0.8242 - val_loss: 18.1058 - val_accuracy: 0.0607\n",
            "Epoch 269/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8573 - accuracy: 0.8183 - val_loss: 18.2110 - val_accuracy: 0.0607\n",
            "Epoch 270/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8668 - accuracy: 0.8185 - val_loss: 18.2177 - val_accuracy: 0.0698\n",
            "Epoch 271/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8785 - accuracy: 0.8192 - val_loss: 18.2819 - val_accuracy: 0.0530\n",
            "Epoch 272/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9394 - accuracy: 0.8036 - val_loss: 18.2894 - val_accuracy: 0.0646\n",
            "Epoch 273/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.9002 - accuracy: 0.8077 - val_loss: 18.1570 - val_accuracy: 0.0620\n",
            "Epoch 274/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8642 - accuracy: 0.8197 - val_loss: 18.3777 - val_accuracy: 0.0685\n",
            "Epoch 275/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8583 - accuracy: 0.8210 - val_loss: 18.2874 - val_accuracy: 0.0646\n",
            "Epoch 276/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8690 - accuracy: 0.8222 - val_loss: 18.5848 - val_accuracy: 0.0607\n",
            "Epoch 277/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8697 - accuracy: 0.8157 - val_loss: 18.4211 - val_accuracy: 0.0646\n",
            "Epoch 278/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8540 - accuracy: 0.8154 - val_loss: 18.3519 - val_accuracy: 0.0672\n",
            "Epoch 279/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8125 - accuracy: 0.8361 - val_loss: 18.2858 - val_accuracy: 0.0607\n",
            "Epoch 280/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8514 - accuracy: 0.8164 - val_loss: 18.1730 - val_accuracy: 0.0633\n",
            "Epoch 281/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8337 - accuracy: 0.8228 - val_loss: 18.1987 - val_accuracy: 0.0685\n",
            "Epoch 282/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8587 - accuracy: 0.8170 - val_loss: 18.2154 - val_accuracy: 0.0568\n",
            "Epoch 283/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8306 - accuracy: 0.8217 - val_loss: 18.0983 - val_accuracy: 0.0659\n",
            "Epoch 284/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8286 - accuracy: 0.8247 - val_loss: 18.3034 - val_accuracy: 0.0530\n",
            "Epoch 285/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8558 - accuracy: 0.8100 - val_loss: 18.3346 - val_accuracy: 0.0736\n",
            "Epoch 286/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8408 - accuracy: 0.8201 - val_loss: 18.1310 - val_accuracy: 0.0581\n",
            "Epoch 287/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8514 - accuracy: 0.8107 - val_loss: 18.1553 - val_accuracy: 0.0543\n",
            "Epoch 288/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8400 - accuracy: 0.8203 - val_loss: 18.1368 - val_accuracy: 0.0581\n",
            "Epoch 289/300\n",
            "97/97 [==============================] - 8s 78ms/step - loss: 0.8457 - accuracy: 0.8096 - val_loss: 18.1866 - val_accuracy: 0.0620\n",
            "Epoch 290/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8409 - accuracy: 0.8115 - val_loss: 18.1179 - val_accuracy: 0.0711\n",
            "Epoch 291/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8571 - accuracy: 0.8116 - val_loss: 18.1968 - val_accuracy: 0.0620\n",
            "Epoch 292/300\n",
            "97/97 [==============================] - 8s 77ms/step - loss: 0.8503 - accuracy: 0.8233 - val_loss: 18.2957 - val_accuracy: 0.0633\n",
            "Epoch 293/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8670 - accuracy: 0.8120 - val_loss: 18.2522 - val_accuracy: 0.0685\n",
            "Epoch 294/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8180 - accuracy: 0.8197 - val_loss: 18.2281 - val_accuracy: 0.0698\n",
            "Epoch 295/300\n",
            "97/97 [==============================] - 8s 77ms/step - loss: 0.8269 - accuracy: 0.8240 - val_loss: 18.2265 - val_accuracy: 0.0607\n",
            "Epoch 296/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8726 - accuracy: 0.8051 - val_loss: 18.1811 - val_accuracy: 0.0620\n",
            "Epoch 297/300\n",
            "97/97 [==============================] - 7s 75ms/step - loss: 0.8386 - accuracy: 0.8054 - val_loss: 18.0677 - val_accuracy: 0.0633\n",
            "Epoch 298/300\n",
            "97/97 [==============================] - 7s 77ms/step - loss: 0.8087 - accuracy: 0.8239 - val_loss: 18.0766 - val_accuracy: 0.0711\n",
            "Epoch 299/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.8028 - accuracy: 0.8150 - val_loss: 18.0967 - val_accuracy: 0.0672\n",
            "Epoch 300/300\n",
            "97/97 [==============================] - 7s 76ms/step - loss: 0.7895 - accuracy: 0.8219 - val_loss: 18.0882 - val_accuracy: 0.0711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "xfQl71U3-ECa",
        "outputId": "97e8e34b-1c92-4cbd-9839-b3a0e163686b"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(history.history.keys())\r\n",
        "#  \"Accuracy\"\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "# \"Loss\"\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr3ejAt5PoD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80b31b2-86e5-4492-9a54-44c6787c52e7"
      },
      "source": [
        "#save model\r\n",
        "model.save('/content/drive/MyDrive/ai_poeta/', overwrite=True, include_optimizer=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ai_poeta/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ai_poeta/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXZ7Sj8HSbFY"
      },
      "source": [
        "#load our saved model\r\n",
        "import keras # we repeat only for loading our saved model case\r\n",
        "model = keras.models.load_model('/content/drive/MyDrive/ai_poeta/')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQd1r3R1DPMv"
      },
      "source": [
        "Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEYM5apgUDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126ee7e1-f9d1-45e3-e2c7-4929eaf93042"
      },
      "source": [
        "starting_word = \"Heart pain\" #Put here some  sequence you want our AI to start from...\r\n",
        "words_number = 30 #you can change this number, if you prefer longer or shorter \r\n",
        "#text to be generated\r\n",
        "  \r\n",
        "for _ in range(words_number):\r\n",
        "\ttoken_list = tokenizer.texts_to_sequences([starting_word])[0]\r\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\r\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\r\n",
        "\toutput_word = \"\"\r\n",
        "\tfor word, index in tokenizer.word_index.items():\r\n",
        "\t\tif index == predicted:\r\n",
        "\t\t\toutput_word = word\r\n",
        "\t\t\tbreak\r\n",
        "\tstarting_word += \" \" + output_word"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd6Kc6ehSMRb",
        "outputId": "b4e6abd4-afdf-4fc1-fb65-8ba90256dfab"
      },
      "source": [
        "from collections import Counter\r\n",
        "\r\n",
        "#y = starting_word.split(\" \")\r\n",
        "    \r\n",
        "#print(starting_word.replace(' ', '\\n'))\r\n",
        "\r\n",
        "for i in range(0,30,5):\r\n",
        "    print(starting_word.split(' ')[i], starting_word.split(' ')[i+1],\r\n",
        "          starting_word.split(' ')[i+2], starting_word.split(' ')[i+3],\r\n",
        "          starting_word.split(' ')[i+4])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Heart pain with sunlight man\n",
            "to find his way by\n",
            "my great betray put in\n",
            "her heart to be loved\n",
            "my people in they people\n",
            "when from they gaze meant\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}